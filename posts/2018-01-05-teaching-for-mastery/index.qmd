---
title: "Teaching for Mastery"
date: 2018-01-05
categories: ["teaching", "learning", "ideas"]
---

```{r}
#| label: libraries
#| echo: !expr F
#| message: !expr F
#| warning: !expr F

library(ggplot2)
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(cowplot))
library(tidyr)

```

## Grading on Progress

Grades are typically set in absolute terms: you either get the points or you don't. It doesn't matter where you started, it doesn't matter how fast you learn. You either get the points or you don't. Grading on progress takes a different approach to certifying achievement.

Intuitively, it makes sense, if two people made the same amount of progress, they should get the same reward. But the way in which we interact with grades is different. We are trying to get a quantity that represents **achievement**. Particularly, we are interested in the degree of achievement of the learning goals set at the beginning of the course by the professor and the students. I understand that this treats knowledge as a commodity that can be obtained and accumulated. While I believe that reality is a bit more complex, I think this is a good starting point for our discussion.

So...How much do students learn anyway? That is a difficult question, let's simplify by assuming some conditions:

1.  We have set achievable learning objectives/goals.
2.  We test often.
3.  Our testing method is valid and graded fairly.
4.  We obtain an accurate representation of whatever is inside our students brains (aka "knowledge").
5.  Students put roughly the same amount of effort.
6.  Students put enough effort for the task.
7.  Our teaching method is effective in increasing student's knowledge of the subject.

If these were true, we would then likely see that our students make progress at roughly the same rate. But progress rate has its caveats. Let's choose two students. It happens that one of them came to the course with bit more knowledge on the subject matter than the other. Given the assumptions listed above, here's one possible outcome.

```{r}
#| label: grading_progres
#| echo: !expr F

# set seed
set.seed(123456)


# We will do all the data here so it's available
# General time

mytime <- seq(0, 100, 1)

# Student A knows 40 % of the knowledge and will get to 80% 
# (delta Knowledge = 40%)
studentA <- 0.4 * mytime - rnorm(1, mean = 0, sd= 10) + 40
# Student B learns at the same rate (0.4), but knows only 10%
studentB <- 0.4 * mytime - rnorm(1, mean = 0, sd= 10) + 10
# we need to fix in case we go below zero
studentB <- ifelse(studentB < 0, 0, studentB)
# Student that passes but does not learn much (change ~ 0)
studentC <- 0.0004 * mytime - rnorm(1, mean =0, sd=10) + 75

# Fast and slow students for final graph

Faster <- 4 * mytime

# max is 100
Faster[Faster>100] <- 100

Slower <- ifelse(mytime<40, 0.04 * mytime, 1.2 * mytime)

Slower[Slower>100] <- 100

### Data for this chunck
para_progress <- pivot_longer(data.frame(time=mytime, studentA=studentA, studentB=studentB), cols = -time)

# sample 20 steps
mysamples <- sample(x = unique(para_progress$time), size = 20)
para_progress <- para_progress %>%
                 filter(time %in% mysamples) %>%
                 rename(student=name,
                        knowledge=value)

para_progress %>% 
  ggplot(aes(time, knowledge, color=student)) +
  geom_hline(yintercept = 60, lty=2) +
  geom_step() +
  geom_point(size=2, alpha=0.8) + 
  scale_color_manual(values = c("#44AA99", "#DDAA77")) +
  theme(legend.position="bottom")+
  labs(y = "Cumulative Knowledge (%)", 
       title = "Student Progress",
       subtitle = "Setting arbitrary thresholds punishes students who start with lesser background",
       x = "Time in class (days)") +
  ylim(c(0,100))+
  geom_text(data = data.frame(x=5, y=c(55,65), 
                              label=c("Fail", "Pass")),
            mapping = aes(x,y,label=label), 
            inherit.aes=FALSE)
```

We can look at the performance summary in the following table. Both students performed similarly (`change` column) , but they didn't come with the same background (`min` column). Thus, the cumulative knowledge/score is higher for `studentA` (`max` column).

```{r}
#| label: table_1
#| echo: !expr F

table_1 <- para_progress %>% 
  group_by(student) %>% 
  summarise(min=round(min(knowledge),2), 
            max=round(max(knowledge),2),
            change = max(knowledge)-min(knowledge))

knitr::kable(table_1)


```

### What to do?

Grading on progress put us in a conflict. If measuring progress, both students should be graded equally. But a criterion-based method tells us otherwise. Whenever there's a critical amount of knowledge, it might be the case that some students fail to achieve it. Lowering the bar is not an option. Problems like this one do not arise because we chose the limit at 60%. Problems like this one arise because the arbitrary limit exists. There are options to solve the `Pass/Fail` issue. We can switch to setting a limit for the amount of progress students make in our classroom. However, setting an arbitrary limit for the amount of progress students make will still generate problems. Most importantly, in such a method, **passing students fail to achieve criteria**.

Maybe our assumptions are wrong, maybe not all the students learn at the same rate. Let's take another case.

```{r}
#| label: inter_progress
#| echo: !expr F

# Data frame with interaction

inter_progress <- pivot_longer(data.frame(time=mytime, studentB=studentB, studentC=studentC), cols = -time)

# Filter random samples

inter_progress <- inter_progress %>%
                 filter(time %in% mysamples) %>%
                 rename(student=name,
                        knowledge=value)


inter_progress %>% 
  ggplot(aes(time, knowledge, color=student)) +
  geom_hline(yintercept = 60, lty=2) +
  geom_step()+
  geom_point(size=2, alpha=0.8) + 
  scale_color_manual(values = c("#DDAA77", "#AA4499")) +
  theme(legend.position="bottom")+
  ylim(c(0,100))+
  geom_text(data = data.frame(x=5, y=c(55,66), 
                              label=c("Fail", "Pass")),
            aes(x,y,label=label), 
            inherit.aes=FALSE) +
  labs(y = "Cumulative Knowledge (%)", 
       title = "Student Progress",
       subtitle = "Students who learn fail to pass while students who know but fail to learn do.",
       x = "Time in class (days)")





```

Let's take a look at the summary table.

```{r}
#| label: table_2
#| echo: !expr F

table_2 <- inter_progress %>% 
  group_by(student) %>% 
  summarise(min=round(min(knowledge),2), 
            max= round(max(knowledge),2),
            change = round(max(knowledge)-min(knowledge),2))

knitr::kable(table_2)


```

In this case, if we chose to grade on progress, we would produce a counter-intuitive result. Absurd example aside, we can argue that `studentC` is overqualified for the course. But the truth is, this student hasn't *mastered* the material yet. Wouldn't it be great if all students got to 100%?

## Mastery

Wait a minute... Shouldn't we aim to get our students to know *all* the material? Aiming for mastery implies that the bar is at 100%. It also means that advancement to the next level requires achieving all learning outcomes.

This might sound as too tough, but learning new material involves adding the new information to the network of already established concepts in our brain. We can think of it as adding a new floor to a building. We can't afford to let gaps in knowledge propagate year after year, just as we can't add floors to a skyscraper with terrible foundations or gaps in the middle. We can't afford gap propagation, even for small gaps. Salman Khan explains it better than me [here](https://www.ted.com/talks/sal_khan_let_s_teach_for_mastery_not_test_scores), if you get anything from this article, I wish it's the next quote:

> Teaching for Mastery is not a nice to have, it's a social imperative. - Salman Khan

## The path

The path matters. We can think about learning in terms of packets of knowledge, cumulative unlocked skills or mini level-up moments. Let's take a look at the journey of `studentA` and `studentB`.

```{r}
#| label: path_plot_1
#| echo: !expr F

arrows <- 
  tibble(
    x1 = c(50, 50),
    x2 = c(30, 30),
    y1 = c(80, 80), 
    y2 = c(45, 25),
  )

para_progress %>% 
  ggplot(aes(time, knowledge, color=student)) +
  geom_hline(yintercept = 60, lty=2) +
  geom_step() +
  geom_point(size = 2, alpha=0.8) +
  scale_color_manual(values = c("#44AA99", "#DDAA77")) +
  theme(legend.position="bottom")+
  labs(y = "Cumulative Knowledge (%)", 
       x = "Time in class (days)",
       title = "Student Progress",
       subtitle = "All students struggle. Arbitrary limits makes them seem different.") +
  geom_curve(
    data = arrows, 
    aes(x = x1, y = y1, xend = x2, yend = y2),
    arrow = arrow(length = unit(0.08, "inch")), 
    curvature = 0.3,
    linewidth = 0.5,
    color = "gray20",
  ) +
  ylim(c(0,100))+
  geom_text(data = data.frame(x=65, y=80, label="Both Students Struggle"), aes(x,y,label=label), inherit.aes=FALSE)

```

These students are *very similar*. In fact, we can see them struggling to get some concepts (check the colored region). Still, an arbitrary limit makes them look different.

## The time constrain

Teaching for mastery requires that we flip over the constrains. Normally, we would constrain on time. Students have `x` weeks to get the cumulative percent that we considered *good enough*. That creates gaps in knowledge. Forcing students to advance to a new level will propagate those gaps.

Instead of advancing students with gaps in knowledge by constraining time, we could constrain knowledge. All students should get to 100%. If students needed more time to acquire a particular skill or solve a particular type of problem, they should be allowed to take it. By teaching this way, we reinforce resilience and promote the correct mindset for problem solving.

Using current technologies, it is possible to teach individualized lessons and track individual knowledge[^1]. If we use this strategy we need to deal with differences between a fast learner[^2] and one that got stuck in a concept for longer. Here's how the paths would look like.

[^1]: Visit [Khan Academy](www.khanacademy.org)

[^2]: When I say *fast* I do not mean to generalize, it's just for the sake of argument. Fast as in "a student that took less time to master that particular material".

```{r}
#| label: fast_slow
#| echo: !expr F

fast_progress <- pivot_longer(data.frame(time=mytime, Faster=Faster, Slower=Slower), cols = -time)

# Filter random samples

fast_progress <- fast_progress %>%
                 filter(time %in% mysamples) %>%
                 rename(student=name,
                        knowledge=value)


fast_progress %>% ggplot(aes(time, knowledge, color=student)) +
  geom_hline(yintercept = 100, lty=2) +
  geom_point(size=2, alpha=0.8) + 
  geom_step() +
  scale_color_manual(values = c("#DDAA77", "#AA4499")) +
  theme(legend.position="bottom")+
  #geom_vline(xintercept= 27, lty=2)+
  labs(y = "Cumulative Knowledge (%)",
       title = "Student Progress",
       subtitle = "Both Faster and Slower learners should reach Mastery",
       x = "Time in class (days)") + 
  scale_y_continuous(limits = c(0, 110), breaks = seq(0, 100, 25)) +
  ggtitle("Student Progress")+
  geom_text(data = data.frame(x=5, y=c(95,105), 
                              label=c("In-Progress", "Master")),
            aes(x,y,label=label), inherit.aes=FALSE)+
  geom_text(data = data.frame(x=35, y=c(105), label="*"), aes(x,y,label=label), size=8, inherit.aes=FALSE)



```

We can see that one student mastered the content before the other. There's no problem with that. In fact, speed differences already happen in the current system and faster students disengage because there's no further development to go after. The big advantage of teaching for mastery is that we have options, at the moment marked with an asterisk `*` we could:

1)  Promote the student to the next level.
2)  Promote the student to be `peer mentor`.
3)  Both options at the same time.

The first option is the more individualistic. If one made progress at a faster pace, one should be allowed to move forward with more content. Here we have a first difference with the current system. Currently, students are put together by age, as if that were the only variable that determined their capabilities. Teachers have to go a long way outside the comfort zone to give extra assignments to these students. Faster students become a burden instead of a bliss. When the content is already being delivered individually by design, there is no extra effort to pump more advanced material to fast learners.

The second option allows the student to engage in fulfilling activities and enhance even more their confidence with the topic. To be able to mentor a student or teach a topic, you have to have mastered the content *and* be able to communicate it in a way the other mind can understand. Fostering empathetic relationships brings a social element to the classroom, priming students to a real-life experience in collaborative environment. Additionally, students that teach interact with the topic in different ways than traditional students. Peer mentors gain a complete new dimension by having to exercise different approaches to solve a problem or convey an argument.

There are good arguments for having classrooms with small age differences. Sociability among students is heavily influenced by age and there are particular moments in development where two years of difference means a lot. Thus, exploring both options could be a good trade off for students. Given a student was able to master the material, now she has the opportunity to continue forward. But she also has the responsibility to help fellow students who are struggling. It sounds like a win-win situation to me.
